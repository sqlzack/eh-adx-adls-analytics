{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Storage Account Parameters\n",
        "storageAccountName      = \"\"\n",
        "storageAccountContainer = \"\"\n",
        "storageAccountDirectory = \"\" # do not include a leading slash\n",
        "storageLinkedServiceName = \"\"\n",
        "\n",
        "# Event Hub Paramaters\n",
        "keyVaultName = \"\"\n",
        "linkedServiceName = \"\"\n",
        "secretName = \"\"\n",
        "ehName = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "storageAccountFullPath  = f'abfss://{storageAccountContainer}@{storageAccountName}.dfs.core.windows.net/{storageAccountDirectory}'\n",
        "\n",
        "mssparkutils.fs.mount(storageAccountFullPath,\"/faredata_raw\",{\"linkedService\":storageLinkedServiceName}) \n",
        "\n",
        "jobId = mssparkutils.env.getJobId()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "mssparkutils.fs.ls(f\"synfs:/{jobId}/faredata_raw\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pip install azure-eventhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from multiprocessing.connection import wait\n",
        "from multiprocessing.sharedctypes import Value\n",
        "from os import environ\n",
        "from azure.eventhub.aio import EventHubProducerClient\n",
        "from azure.eventhub import EventData\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "import io\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "dir = f'/synfs/{jobId}/faredata_raw'\n",
        "ehConnectionString = mssparkutils.credentials.getSecret(keyVaultName,secretName,linkedServiceName)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def getCSVFiles():\n",
        "    csvCount=0\n",
        "    listCSVs = []\n",
        "\n",
        "    for child in Path(dir).glob('*.csv'):\n",
        "        listCSVs.append(child)\n",
        "        csvCount += 1\n",
        "    \n",
        "    return csvCount,listCSVs\n",
        "\n",
        "# Function to send to Event Hubs\n",
        "async def main(listOfLines):\n",
        "    # Create a producer client to send messages to the event hub.\n",
        "    # Specify a connection string to your event hubs namespace and\n",
        "    # the event hub name.\n",
        "    producer = EventHubProducerClient.from_connection_string(conn_str=ehConnectionString, eventhub_name=ehName)\n",
        "    async with producer:\n",
        "        # Create a batch.\n",
        "        event_data_batch = await producer.create_batch()\n",
        "\n",
        "        # Add events to the batch.\n",
        "        for line in listOfLines:\n",
        "            event_data_batch.add(EventData(line))\n",
        "        \n",
        "        # Send the batch of events to the event hub.\n",
        "        await producer.send_batch(event_data_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ctCsvFiles, csvFiles = getCSVFiles()\n",
        "for csvFile in csvFiles:\n",
        "    openFile = io.open(csvFile,'r')\n",
        "    count = 0\n",
        "    print(f\"Starting {csvFile}\")\n",
        "    lineList = []\n",
        "\n",
        "    while True:\n",
        "        count +=1\n",
        "\n",
        "        line = openFile.readline().strip()\n",
        "\n",
        "        # I guarantee there's a more elegant way to do this. However, I want to control the number of lines going through and how they are shaped.\n",
        "        if line.startswith(\"medallion\") == False and line != \"\":\n",
        "            splitLine       = line.split(\",\")\n",
        "            buildJsonString = \"{\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"medallion\\\":\\\"{splitLine[0]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"hack_license\\\":\\\"{splitLine[1]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"vendor_id\\\":\\\"{splitLine[2]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"pickup_datetime\\\":\\\"{splitLine[3]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"payment_type\\\":\\\"{splitLine[4]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"fare_amount\\\":\\\"{splitLine[5]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"surcharge\\\":\\\"{splitLine[6]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"mta_tax\\\":\\\"{splitLine[7]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"tip_amount\\\":\\\"{splitLine[8]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"tolls_amount\\\":\\\"{splitLine[9]}\\\",\"\n",
        "            buildJsonString = f\"{buildJsonString}\\\"total_amount\\\":\\\"{splitLine[10]}\\\"\"\n",
        "            buildJsonString = f\"{buildJsonString}}}\"\n",
        "            lineList.append(buildJsonString)        \n",
        "\n",
        "        if count % 3500 == 0:\n",
        "            try:\n",
        "                await(main(lineList))\n",
        "            except Exception as e:\n",
        "                print(f\"Batch {count} in file {csvFile} failed to send to Event Hubs\")\n",
        "                print(e)\n",
        "            finally:                \n",
        "                lineList = []\n",
        "\n",
        "        if count % 12000 == 0:\n",
        "            print(f\"{count} lines sent\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        if not line:\n",
        "            break\n",
        "    \n",
        "    # Send remaining lines to event hubs since not all files will show a remainder of 0 when dividing by 3500\n",
        "    if count % 3500 != 0:\n",
        "        try:\n",
        "            await(main(lineList))\n",
        "        except Exception as e:\n",
        "            print(f\"Batch {count} in file {csvFile} failed to send to Event Hubs\")\n",
        "            print(e)\n",
        "        finally:                \n",
        "            lineList = []\n",
        "    \n",
        "    openFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "mssparkutils.fs.unmount(\"/faredata_raw\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "e73eccf3cecfe0fa83495263941eee6734b1826b1b1330d30f19d544477409ea"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
